import json
import os
import time
from .state import ProjectState
from .providers.gemini import GeminiProvider
from .providers.researcher import ResearcherProvider
from .providers.strategist import StrategistProvider
from .providers.compliance import ComplianceProvider
from .config import config
from .parallel_utils import (
    ParallelImageGenerator,
    ParallelAudioGenerator,
    ParallelVideoGenerator,
    CharacterConsistencyExtractor,
    SmartCritiqueCache
)

class AdGenerator:
    """The Orchestrator."""
    
    def __init__(self, project_id: str = None):
        if project_id:
            self.state = ProjectState(id=project_id, user_input="")
        else:
            self.state = ProjectState(user_input="")
        self.llm = GeminiProvider()
        self.researcher = ResearcherProvider()
        self.strategist = StrategistProvider()
        self.compliance = ComplianceProvider()
        
    def _get_plan_path(self):
        return os.path.join(config.OUTPUT_DIR, f"plan_{self.state.id}.json")

    def plan(self, user_input: str, config_overrides: dict = None) -> dict:
        """
        Phase 2: The Brain.
        Generates the cinematic plan and saves it to plan_{id}.json.

        Args:
            user_input: User's creative brief or URL
            config_overrides: Optional dict from UI with style, duration, platform, mood, url
                Example: {"style": ["Cinematic"], "url": "http...", "mood": "Premium"}
        """
        self.state.user_input = user_input
        self.state.update_status("planning")
        
        # Ensure config_overrides is always a dict to avoid NoneType errors
        if config_overrides is None:
            config_overrides = {}

        # Phase 1.5: Research (if URL provided in input OR config)
        context = user_input
        industry = "General"
        website_data = ""
        
        # Check for URL in config_overrides first (new UI), then user_input (legacy)
        target_url = config_overrides.get('url') if config_overrides else None
        if not target_url and user_input.startswith("http"):
            target_url = user_input

        if target_url:
            print(f"[URL] Detected: {target_url}. Launching Researcher...")
            self.state.add_log(f"[RESEARCH] Analyzing target URL: {target_url}...")
            brief = self.researcher.fetch_and_analyze(target_url)
            print(f"[RESEARCH] Brief:\n{brief[:500]}...")
            self.state.add_log(f"[RESEARCH] Site analysis complete. Extracted {len(brief)} chars of context.")
            context = brief
            website_data = brief
            # Simple heuristic to extract industry from brief for compliance
            if "Industry:" in brief:
                try:
                    industry = brief.split("Industry:")[1].split("\n")[0].strip()
                except:
                    pass
            
            # Save brief to state
            self.state.research_brief = brief

        print(f"[BRAIN] Brainstorming cinematic ad concept...")
        self.state.add_log(f"[STRATEGY] Initializing creative brainstorm for: {user_input}")

        # Phase 1.8: The Strategist (Smart Agent Layer)
        # Synthesize strategy from Topic + Website Data + Constraints
        strategy = self.strategist.develop_strategy(
            topic=user_input,
            website_data=website_data,
            constraints=config_overrides or {}
        )
        self.state.add_log(f"[STRATEGY] Strategic angle developed: {strategy.get('angle', 'N/A')}")

        # Save strategy to state
        self.state.strategy = strategy

        # Call Gemini with Strategy + Config
        self.state.add_log(f"[GEMINI] Generating cinematic screenplay & shotlist...")
        script = self.llm.generate_plan(
            user_input=user_input, 
            config_overrides=config_overrides,
            strategy=strategy
        )
        self.state.add_log(f"[GEMINI] Screenplay generated with {len(script.scenes)} scenes.")

        # Phase 2.5: Compliance Check
        script = self.compliance.review(script, industry=industry)

        self.state.script = script

        # Extract and save frontend cinematography preferences to state
        if config_overrides:
            # Save transition preference for later use in Composer
            if config_overrides.get('transition'):
                # Map frontend transition names to FFmpeg xfade filter names
                transition_map = {
                    "Crossfade": "crossfade",
                    "Fade": "fade",
                    "Wipe": "wipe",
                    "Slide": "slide",
                    "Cut": "cut",
                }
                frontend_transition = config_overrides.get('transition')
                self.state.transition_type = transition_map.get(frontend_transition, "crossfade")

            if config_overrides.get('image_provider'):
                self.state.image_provider = config_overrides.get('image_provider')

            # Save uploaded asset reference
            if config_overrides.get('uploaded_asset'):
                self.state.uploaded_asset = config_overrides.get('uploaded_asset')
            
            # Save multiple uploaded assets
            if config_overrides.get('uploaded_assets'):
                assets = config_overrides.get('uploaded_assets')
                if isinstance(assets, list):
                    self.state.uploaded_assets = assets
                    print(f"[PIPELINE] Received {len(assets)} uploaded assets: {assets}")
                    # Ensure backward compatibility: set primary asset to first one if not set
                    if not self.state.uploaded_asset and len(assets) > 0:
                        self.state.uploaded_asset = assets[0]

        # Apply Strategist Recommendations (if not overridden by User Checkbox)
        if strategy and "production_recommendations" in strategy:
            recs = strategy["production_recommendations"]
            
            # 1. Visual Engine
            if not config_overrides.get('image_provider') and recs.get('visual_engine'):
                rec_engine = recs['visual_engine'].lower()
                if rec_engine in ["flux", "imagen"]:
                    self.state.image_provider = rec_engine
                    print(f"[STRATEGY] Strategist recommends Visual Engine: {rec_engine.upper()}")

            # 2. Video Engine
            if recs.get('video_engine'):
                rec_video = recs['video_engine'].lower()
                if rec_video in ["runway", "veo"]:
                    self.state.video_model = rec_video
                    print(f"[STRATEGY] Strategist recommends Video Engine: {rec_video.upper()}")

        # Update status to planned BEFORE saving
        self.state.update_status("planned")
        self.state.add_log(f"[SYSTEM] PLAN_COMPLETE. Transitioning to Asset Generation Phase.")

        # Save to plan_{id}.json
        plan_path = self._get_plan_path()
        with open(plan_path, "w") as f:
            f.write(self.state.model_dump_json(indent=2))

        print(f"[SUCCESS] Cinematic plan generated and saved to: {plan_path}")

        return self.state.model_dump()

    def resume(self, project_id: str = None):
        """
        Phase 3-6: Execution.
        Loads plan_{id}.json and executes the full pipeline.
        """
        if project_id:
            self.state.id = project_id
            
        plan_path = self._get_plan_path()
        if not os.path.exists(plan_path):
            print(f"[ERROR] No plan found at {plan_path}")
            return

        print(f"[LOAD] Loading plan from: {plan_path}")
        with open(plan_path, "r") as f:
            data = json.load(f)
            self.state = ProjectState(**data)

        print(f"[RESUME] Resuming project: {self.state.user_input}")

        try:
            # --- Phase 3: Assets ---
            print("\n[PHASE 3] Generating Assets...")
            self.state.add_log("[PHASE 3] Starting Asset Generation...")
            # Use real providers for production
            from .providers.imagen import ImagenProvider
            from .providers.flux import FluxProvider
            from .providers.elevenlabs import ElevenLabsProvider
            from .providers.mock import MockElevenLabsProvider
            from .providers.composition import CompositionProvider

            # IMAGE PROVIDER SELECTION:
            # FORCE GOOGLE IMAGEN (Free Tier / User Request)
            # We skip Flux to avoid "Insufficient Credit" errors entirely.
            print("   [VISUALS] Free Tier Active: Using IMAGEN 4 (Standard) + Nano Banana Logic")
            self.state.add_log("[VISUALS] Enforcing Google Ecosystem (Imagen 4 + Gemini)")
            imagen = ImagenProvider()
            
            # Legacy Flux Logic (Disabled for Cost Savings)
            # if config.REPLICATE_API_TOKEN: ... (Commented Out)

            # Use real ElevenLabs if API key configured, otherwise use mock
            try:
                if config.ELEVENLABS_API_KEY and config.ELEVENLABS_API_KEY != "mock_elevenlabs_key":
                    eleven = ElevenLabsProvider()  # Real ElevenLabs for voice/SFX
                    print("   Using ElevenLabs for audio generation")
                else:
                    eleven = MockElevenLabsProvider()  # Mock audio (for testing)
                    print("   Using Mock audio provider (ElevenLabs API key not configured)")
            except Exception as e:
                print(f"   [WARN] ElevenLabs init failed, using mock: {e}")
                eleven = MockElevenLabsProvider()

            composer_tool = CompositionProvider()

            # Visuals - PARALLEL GENERATION with Character Consistency
            print(f"\n   [OPTIMIZATION] Using parallel image generation (3x faster)")
            self.state.add_log("[OPTIMIZATION] Parallel image generation enabled")

            # Check for uploaded asset (Image-to-Image)
            uploaded_asset_path = None
            if self.state.uploaded_asset:
                possible_path = os.path.join(config.ASSETS_DIR, "user_uploads", self.state.uploaded_asset)
                if os.path.exists(possible_path):
                    uploaded_asset_path = possible_path
                    print(f"   [VISUALS] Using Uploaded Reference: {self.state.uploaded_asset}")

            # Handle composition scenes separately (can't parallelize easily)
            composition_scenes = [s for s in self.state.script.scenes if s.composition_sources and not s.image_path]
            for scene in composition_scenes:
                print(f"   [COMPOSE] Composing scene {scene.id} from {len(scene.composition_sources)} sources...")
                try:
                    scene.image_path = composer_tool.compose(scene.composition_sources, scene.visual_prompt)
                    self.state.add_log(f"[VISUALS] Composed Scene {scene.id}")
                except Exception as e:
                    print(f"   [ERROR] Composition Failed for Scene {scene.id}: {e}")
                    self.state.add_log(f"[ERROR] Composition Failed for Scene {scene.id}: {str(e)}")

            # Parallel generation for standard scenes
            try:
                start_time = time.time()
                parallel_gen = ParallelImageGenerator(imagen, self.llm, self.state)
                self.state.script.scenes = parallel_gen.generate_parallel(
                    self.state.script.scenes,
                    uploaded_asset_path=uploaded_asset_path,
                    max_workers=5  # Increased from 3 for speed
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Image generation completed in {elapsed:.1f}s")
                self.state.add_log(f"[PERFORMANCE] Parallel image generation: {elapsed:.1f}s")

                # Character Consistency Extraction & Injection
                print(f"\n   [OPTIMIZATION] Extracting character consistency...")
                consistency_extractor = CharacterConsistencyExtractor(self.llm)
                self.state.script.scenes = consistency_extractor.inject_consistency_references(
                    self.state.script.scenes
                )
                self.state.add_log("[OPTIMIZATION] Character consistency references injected")

            except Exception as e:
                print(f"   [ERROR] Parallel image generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel generation failed: {str(e)}")

                # Fallback to sequential generation
                print(f"   [FALLBACK] Switching to sequential generation...")
                self.state.add_log("[FALLBACK] Using sequential image generation")

                for scene in self.state.script.scenes:
                    if not scene.image_path and not scene.composition_sources:
                        try:
                            print(f"   Generating Image for Scene {scene.id}...")
                            scene.image_path = imagen.generate_image(
                                scene.visual_prompt,
                                seed=self.state.seed + scene.id,
                                image_input=uploaded_asset_path
                            )
                            self.state.add_log(f"[VISUALS] Scene {scene.id} created (sequential)")
                        except Exception as e2:
                            print(f"   [ERROR] Scene {scene.id} failed: {e2}")
                            self.state.add_log(f"[ERROR] Scene {scene.id} failed: {str(e2)}")

            # Audio - PARALLEL GENERATION (VO, SFX, BGM)
            print(f"\n   [OPTIMIZATION] Using parallel audio generation (3x faster)")
            self.state.add_log("[OPTIMIZATION] Parallel audio generation enabled")

            # Deriving mood from strategy for BGM
            mood_prompt = "Cinematic Ambient"
            if self.state.strategy and 'cinematic_direction' in self.state.strategy:
                mood_notes = self.state.strategy['cinematic_direction'].get('mood_notes', '')
                if mood_notes:
                    mood_prompt = mood_notes

            # Calculate BGM duration
            total_duration = sum(scene.duration for scene in self.state.script.scenes) + 5

            try:
                start_time = time.time()
                parallel_audio = ParallelAudioGenerator(eleven, self.state)
                self.state.bgm_path = parallel_audio.generate_all_audio(
                    self.state.script,
                    bgm_duration=total_duration
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Audio generation completed in {elapsed:.1f}s")
                self.state.add_log(f"[PERFORMANCE] Parallel audio generation: {elapsed:.1f}s")

            except Exception as e:
                print(f"   [ERROR] Parallel audio generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel audio failed: {str(e)}")

                # Fallback to sequential generation
                print(f"   [FALLBACK] Switching to sequential audio generation...")
                self.state.add_log("[FALLBACK] Using sequential audio generation")

                # VO
                for i, line in enumerate(self.state.script.lines):
                    if not line.audio_path:
                        try:
                            print(f"   Generating VO for Line {i+1}...")
                            line.audio_path = eleven.generate_speech(line.text)
                        except Exception as e2:
                            print(f"   [ERROR] VO Line {i+1} failed: {e2}")

                # SFX
                for scene in self.state.script.scenes:
                    if not scene.sfx_path and scene.audio_prompt:
                        try:
                            print(f"   Generating SFX for Scene {scene.id}...")
                            scene.sfx_path = eleven.generate_sfx(scene.audio_prompt)
                        except Exception as e2:
                            print(f"   [ERROR] SFX Scene {scene.id} failed: {e2}")

                # BGM
                if not self.state.bgm_path:
                    try:
                        print(f"   Generating BGM...")
                        self.state.bgm_path = eleven.generate_bgm(mood_prompt, duration=total_duration)
                    except Exception as e2:
                        print(f"   [ERROR] BGM failed: {e2}")
            
            self.save_state()

            # --- Phase 4: Motion ---
            print(f"\n[PHASE 4] Motion Synthesis...")
            self.state.add_log(f"[PHASE 4] Starting Motion Synthesis...")

            # Import video providers: Veo 3.1 Ultra (primary) and Runway (fallback)
            from .providers.video_google import GoogleVideoProvider
            from .providers.runway import RunwayProvider

            # Initialize providers - PREMIUM QUALITY MODE
            veo = GoogleVideoProvider()  # Primary: Veo 3.1 Ultra (highest quality, tied #1 in benchmarks)
            runway = RunwayProvider()  # Fallback: Runway Gen-3 Turbo (speed & reliability)

            # PREMIUM QUALITY: Parallel video generation with Veo 3.1 Ultra
            print(f"   [PREMIUM QUALITY] Parallel video generation with Veo 3.1 Ultra")
            self.state.add_log("[PREMIUM QUALITY] Parallel video generation active (Veo 3.1 Ultra + Runway fallback)")

            try:
                start_time = time.time()
                parallel_video = ParallelVideoGenerator(veo, runway, self.state)
                self.state.script.scenes = parallel_video.generate_parallel(
                    self.state.script.scenes,
                    max_workers=3  # Poll up to 3 videos concurrently
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Video generation completed in {elapsed:.1f}s")
            except Exception as e:
                print(f"   [ERROR] Parallel video generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel video generation failed: {str(e)}")
                # Note: ParallelVideoGenerator has internal Runway fallback, so this is a true failure

            self.save_state()

            # --- Phase 5: Assembly ---
            print("\n[PHASE 5] Final Assembly...")
            self.state.add_log("[PHASE 5] Assembling Final Video...")

            # Validate we have video clips before attempting assembly
            video_clips = [s for s in self.state.script.scenes if s.video_path and os.path.exists(s.video_path)]

            if len(video_clips) == 0:
                error_msg = "No video clips available for assembly. All video generation failed."
                print(f"   [FATAL] {error_msg}")
                self.state.add_log(f"[FATAL] {error_msg}")
                self.state.status = "failed"
                self.state.error = error_msg
                self.save_state()
                raise Exception(error_msg)

            if len(video_clips) < len(self.state.script.scenes):
                missing_count = len(self.state.script.scenes) - len(video_clips)
                print(f"   [WARN] {missing_count} scenes failed video generation, proceeding with {len(video_clips)} clips")
                self.state.add_log(f"[WARN] Partial success: {len(video_clips)}/{len(self.state.script.scenes)} scenes")

            try:
                from .providers.composer import Composer
                composer = Composer()

                # Use transition preference from state (set during plan phase)
                print(f"   [ASSEMBLY] Composing {len(video_clips)} video clips...")
                self.state.add_log(f"[ASSEMBLY] Composing with transition: {self.state.transition_type}")

                final_path = composer.compose(self.state, transition_type=self.state.transition_type)

                if final_path and os.path.exists(final_path):
                    self.state.final_video_path = final_path
                    self.state.status = "completed"
                    self.save_state()
                    print(f"\n[DONE] Video saved to: {final_path}")
                    self.state.add_log(f"[SUCCESS] Final video: {final_path}")
                else:
                    raise Exception("Composer returned invalid path")

            except Exception as e:
                error_msg = f"Assembly failed: {str(e)}"
                print(f"   [ERROR] {error_msg}")
                self.state.add_log(f"[ERROR] {error_msg}")
                self.state.status = "failed"
                self.state.error = error_msg
                self.save_state()
                raise

            # --- Phase 6: Mastering (4K Upscale) ---
            # DISABLED for Free Tier (Topaz/Replicate costs money)
            # if config.REPLICATE_API_TOKEN:
            #     print("\n[PHASE 6] Mastering (4K Topaz Upscale)...")
            #     ...
            self.state.add_log("[MASTERING] 4K Upscale Skipped (Free Tier Active).")

            # Print Performance Summary
            print("\n" + "="*80)
            print("PIPELINE COMPLETE - PERFORMANCE SUMMARY")
            print("="*80)

            # Count successes
            image_success = len([s for s in self.state.script.scenes if s.image_path])
            video_success = len([s for s in self.state.script.scenes if s.video_path])
            vo_success = len([l for l in self.state.script.lines if l.audio_path])
            sfx_success = len([s for s in self.state.script.scenes if s.sfx_path or not s.audio_prompt])

            print(f"Images:  {image_success}/{len(self.state.script.scenes)} scenes")
            print(f"Videos:  {video_success}/{len(self.state.script.scenes)} scenes")
            print(f"VO:      {vo_success}/{len(self.state.script.lines)} lines")
            print(f"SFX:     {sfx_success}/{len(self.state.script.scenes)} scenes")
            print(f"BGM:     {'Yes' if self.state.bgm_path else 'No'}")
            print(f"Final:   {self.state.final_video_path}")
            print("="*80 + "\n")

            self.state.status = "completed"
            self.save_state()

        except Exception as e:
            # Top-level error handler - catches any uncaught exceptions
            error_msg = f"Generation failed: {str(e)}"
            print(f"\n[FATAL ERROR] {error_msg}")
            print(f"[ERROR] Full traceback saved to logs")

            # Add detailed error context to state
            import traceback
            self.state.add_log(f"[FATAL] {error_msg}")
            self.state.add_log(f"[TRACEBACK] {traceback.format_exc()}")

            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()

            # Print what succeeded before failure
            print("\n" + "="*80)
            print("PARTIAL RESULTS BEFORE FAILURE")
            print("="*80)
            image_count = len([s for s in self.state.script.scenes if s.image_path])
            video_count = len([s for s in self.state.script.scenes if s.video_path])
            print(f"Images generated: {image_count}/{len(self.state.script.scenes)}")
            print(f"Videos generated: {video_count}/{len(self.state.script.scenes)}")
            print(f"State saved to: {self._get_plan_path()}")
            print("="*80 + "\n")

            raise  # Re-raise so background task wrapper can catch it

    # ========================================================================================
    # APPROVAL WORKFLOW: Stage-Based Methods for Client Demo
    # ========================================================================================
    # These methods split the resume() pipeline into 3 approval gates:
    # 1. generate_images_only() - Creates images + audio, then STOPS
    # 2. generate_videos_only() - Animates videos, then STOPS
    # 3. assemble_final() - Assembles final video
    # ========================================================================================

    def generate_images_only(self, project_id: str = None):
        """
        APPROVAL GATE 1: Generate images and audio, then STOP.
        Sets status to 'images_complete' when done.
        Frontend polls /status and shows approval UI when this status is reached.
        """
        if project_id:
            self.state.id = project_id

        plan_path = self._get_plan_path()
        if not os.path.exists(plan_path):
            error_msg = f"No plan found at {plan_path}"
            print(f"[ERROR] {error_msg}")
            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise FileNotFoundError(error_msg)

        print(f"[LOAD] Loading plan from: {plan_path}")
        with open(plan_path, "r") as f:
            data = json.load(f)
            self.state = ProjectState(**data)

        print(f"[APPROVAL_GATE_1] Starting image generation for: {self.state.user_input}")
        self.state.status = "generating_images"
        self.state.add_log("[APPROVAL_GATE_1] User approved strategy. Starting image + audio generation...")
        self.save_state()

        try:
            # --- PHASE 3A: Image + Audio Generation (Copied from resume() lines 189-349) ---
            print("\n[PHASE 3A] Generating Images & Audio...")
            self.state.add_log("[PHASE 3A] Starting Asset Generation...")

            from .providers.imagen import ImagenProvider
            from .providers.flux import FluxProvider
            from .providers.elevenlabs import ElevenLabsProvider
            from .providers.mock import MockElevenLabsProvider
            from .providers.composition import CompositionProvider

            # IMAGE PROVIDER SELECTION
            print("   [VISUALS] Free Tier Active: Using IMAGEN 4 (Standard) + Nano Banana Logic")
            self.state.add_log("[VISUALS] Enforcing Google Ecosystem (Imagen 4 + Gemini)")
            imagen = ImagenProvider()

            # Audio provider
            try:
                if config.ELEVENLABS_API_KEY and config.ELEVENLABS_API_KEY != "mock_elevenlabs_key":
                    eleven = ElevenLabsProvider()
                    print("   Using ElevenLabs for audio generation")
                else:
                    eleven = MockElevenLabsProvider()
                    print("   Using Mock audio provider (ElevenLabs API key not configured)")
            except Exception as e:
                print(f"   [WARN] ElevenLabs init failed, using mock: {e}")
                eleven = MockElevenLabsProvider()

            composer_tool = CompositionProvider()

            # Visuals - PARALLEL GENERATION
            print(f"\n   [OPTIMIZATION] Using parallel image generation (3x faster)")
            self.state.add_log("[OPTIMIZATION] Parallel image generation enabled")

            # Check for uploaded asset
            uploaded_asset_path = None
            if self.state.uploaded_asset:
                possible_path = os.path.join(config.ASSETS_DIR, "user_uploads", self.state.uploaded_asset)
                if os.path.exists(possible_path):
                    uploaded_asset_path = possible_path
                    print(f"   [VISUALS] Using Uploaded Reference: {self.state.uploaded_asset}")

            # Handle composition scenes
            composition_scenes = [s for s in self.state.script.scenes if s.composition_sources and not s.image_path]
            for scene in composition_scenes:
                print(f"   [COMPOSE] Composing scene {scene.id} from {len(scene.composition_sources)} sources...")
                try:
                    scene.image_path = composer_tool.compose(scene.composition_sources, scene.visual_prompt)
                    self.state.add_log(f"[VISUALS] Composed Scene {scene.id}")
                except Exception as e:
                    print(f"   [ERROR] Composition Failed for Scene {scene.id}: {e}")
                    self.state.add_log(f"[ERROR] Composition Failed for Scene {scene.id}: {str(e)}")

            # Parallel generation for standard scenes
            try:
                start_time = time.time()
                parallel_gen = ParallelImageGenerator(imagen, self.llm, self.state)
                self.state.script.scenes = parallel_gen.generate_parallel(
                    self.state.script.scenes,
                    uploaded_asset_path=uploaded_asset_path,
                    max_workers=3
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Image generation completed in {elapsed:.1f}s")
                self.state.add_log(f"[PERFORMANCE] Parallel image generation: {elapsed:.1f}s")

                # Character Consistency
                print(f"\n   [OPTIMIZATION] Extracting character consistency...")
                consistency_extractor = CharacterConsistencyExtractor(self.llm)
                self.state.script.scenes = consistency_extractor.inject_consistency_references(
                    self.state.script.scenes
                )
                self.state.add_log("[OPTIMIZATION] Character consistency references injected")

            except Exception as e:
                print(f"   [ERROR] Parallel image generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel generation failed: {str(e)}")

                # Fallback to sequential
                print(f"   [FALLBACK] Switching to sequential generation...")
                self.state.add_log("[FALLBACK] Using sequential image generation")

                for scene in self.state.script.scenes:
                    if not scene.image_path and not scene.composition_sources:
                        try:
                            print(f"   Generating Image for Scene {scene.id}...")
                            scene.image_path = imagen.generate_image(
                                scene.visual_prompt,
                                seed=self.state.seed + scene.id,
                                image_input=uploaded_asset_path
                            )
                            self.state.add_log(f"[VISUALS] Scene {scene.id} created (sequential)")
                        except Exception as e2:
                            print(f"   [ERROR] Scene {scene.id} failed: {e2}")
                            self.state.add_log(f"[ERROR] Scene {scene.id} failed: {str(e2)}")

            # Audio - PARALLEL GENERATION
            print(f"\n   [OPTIMIZATION] Using parallel audio generation (3x faster)")
            self.state.add_log("[OPTIMIZATION] Parallel audio generation enabled")

            # Derive mood from strategy
            mood_prompt = "Cinematic Ambient"
            if self.state.strategy and 'cinematic_direction' in self.state.strategy:
                mood_notes = self.state.strategy['cinematic_direction'].get('mood_notes', '')
                if mood_notes:
                    mood_prompt = mood_notes

            total_duration = sum(scene.duration for scene in self.state.script.scenes) + 5

            try:
                start_time = time.time()
                parallel_audio = ParallelAudioGenerator(eleven, self.state)
                self.state.bgm_path = parallel_audio.generate_all_audio(
                    self.state.script,
                    bgm_duration=total_duration
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Audio generation completed in {elapsed:.1f}s")
                self.state.add_log(f"[PERFORMANCE] Parallel audio generation: {elapsed:.1f}s")

            except Exception as e:
                print(f"   [ERROR] Parallel audio generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel audio failed: {str(e)}")

                # Fallback to sequential
                print(f"   [FALLBACK] Switching to sequential audio generation...")
                self.state.add_log("[FALLBACK] Using sequential audio generation")

                # VO
                for i, line in enumerate(self.state.script.lines):
                    if not line.audio_path:
                        try:
                            print(f"   Generating VO for Line {i+1}...")
                            line.audio_path = eleven.generate_speech(line.text)
                        except Exception as e2:
                            print(f"   [ERROR] VO Line {i+1} failed: {e2}")

                # SFX
                for scene in self.state.script.scenes:
                    if not scene.sfx_path and scene.audio_prompt:
                        try:
                            print(f"   Generating SFX for Scene {scene.id}...")
                            scene.sfx_path = eleven.generate_sfx(scene.audio_prompt)
                        except Exception as e2:
                            print(f"   [ERROR] SFX Scene {scene.id} failed: {e2}")

                # BGM
                if not self.state.bgm_path:
                    try:
                        print(f"   Generating BGM...")
                        self.state.bgm_path = eleven.generate_bgm(mood_prompt, duration=total_duration)
                    except Exception as e2:
                        print(f"   [ERROR] BGM failed: {e2}")

            # APPROVAL GATE: Mark as complete and STOP
            self.state.status = "images_complete"
            print(f"\n[APPROVAL_GATE_1] Images + Audio Complete!")
            print(f"[APPROVAL_GATE_1] Waiting for user approval to proceed to video generation...")
            self.state.add_log("[APPROVAL_GATE_1] Images + Audio complete. Awaiting user approval...")

            # Print summary for frontend
            image_success = len([s for s in self.state.script.scenes if s.image_path])
            print(f"   Images:  {image_success}/{len(self.state.script.scenes)} scenes")
            print(f"   VO:      {len([l for l in self.state.script.lines if l.audio_path])}/{len(self.state.script.lines)} lines")
            print(f"   BGM:     {'Yes' if self.state.bgm_path else 'No'}")

            self.save_state()

        except Exception as e:
            error_msg = f"Image generation failed: {str(e)}"
            print(f"\n[FATAL ERROR] {error_msg}")

            import traceback
            self.state.add_log(f"[FATAL] {error_msg}")
            self.state.add_log(f"[TRACEBACK] {traceback.format_exc()}")

            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise

    def generate_videos_only(self, project_id: str = None):
        """
        APPROVAL GATE 2: Generate videos from existing images, then STOP.
        Sets status to 'videos_complete' when done.
        Frontend polls /status and shows approval UI when this status is reached.
        """
        if project_id:
            self.state.id = project_id

        plan_path = self._get_plan_path()
        if not os.path.exists(plan_path):
            error_msg = f"No plan found at {plan_path}"
            print(f"[ERROR] {error_msg}")
            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise FileNotFoundError(error_msg)

        print(f"[LOAD] Loading plan from: {plan_path}")
        with open(plan_path, "r") as f:
            data = json.load(f)
            self.state = ProjectState(**data)

        print(f"[APPROVAL_GATE_2] Starting video generation for: {self.state.user_input}")
        self.state.status = "generating_videos"
        self.state.add_log("[APPROVAL_GATE_2] User approved images. Starting video generation...")
        self.save_state()

        try:
            # --- PHASE 4: Motion Synthesis ---
            print(f"\n[PHASE 4] Motion Synthesis...")
            self.state.add_log(f"[PHASE 4] Starting Motion Synthesis...")

            # Import video providers: Runway and Veo (Kling removed per user request)
            from .providers.video_google import GoogleVideoProvider
            from .providers.runway import RunwayProvider

            runway = RunwayProvider()
            veo = GoogleVideoProvider()

            # OPTIMIZATION: Parallel video generation (-60 seconds per commercial)
            print(f"   [OPTIMIZATION] Parallel video generation enabled (submit-all-then-poll)")
            self.state.add_log("[OPTIMIZATION] Parallel video generation active (Runway + Veo fallback)")

            try:
                start_time = time.time()
                parallel_video = ParallelVideoGenerator(runway, veo, self.state)
                self.state.script.scenes = parallel_video.generate_parallel(
                    self.state.script.scenes,
                    max_workers=3  # Poll up to 3 videos concurrently
                )
                elapsed = time.time() - start_time
                print(f"   [PERFORMANCE] Video generation completed in {elapsed:.1f}s")
            except Exception as e:
                print(f"   [ERROR] Parallel video generation failed: {e}")
                self.state.add_log(f"[ERROR] Parallel video generation failed: {str(e)}")

            # APPROVAL GATE: Mark as complete and STOP
            self.state.status = "videos_complete"
            print(f"\n[APPROVAL_GATE_2] Video Generation Complete!")
            print(f"[APPROVAL_GATE_2] Waiting for user approval to proceed to final assembly...")
            self.state.add_log("[APPROVAL_GATE_2] Videos complete. Awaiting user approval...")

            # Print summary
            video_success = len([s for s in self.state.script.scenes if s.video_path])
            print(f"   Videos:  {video_success}/{len(self.state.script.scenes)} scenes")

            self.save_state()

        except Exception as e:
            error_msg = f"Video generation failed: {str(e)}"
            print(f"\n[FATAL ERROR] {error_msg}")

            import traceback
            self.state.add_log(f"[FATAL] {error_msg}")
            self.state.add_log(f"[TRACEBACK] {traceback.format_exc()}")

            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise

    def assemble_final(self, project_id: str = None):
        """
        APPROVAL GATE 3: Assemble final video from existing clips.
        Sets status to 'completed' when done.
        """
        if project_id:
            self.state.id = project_id

        plan_path = self._get_plan_path()
        if not os.path.exists(plan_path):
            error_msg = f"No plan found at {plan_path}"
            print(f"[ERROR] {error_msg}")
            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise FileNotFoundError(error_msg)

        print(f"[LOAD] Loading plan from: {plan_path}")
        with open(plan_path, "r") as f:
            data = json.load(f)
            self.state = ProjectState(**data)

        print(f"[APPROVAL_GATE_3] Starting final assembly for: {self.state.user_input}")
        self.state.status = "assembling"
        self.state.add_log("[APPROVAL_GATE_3] User approved videos. Starting final assembly...")
        self.save_state()

        try:
            # --- PHASE 5: Assembly (Copied from resume() lines 436-512) ---
            print("\n[PHASE 5] Final Assembly...")
            self.state.add_log("[PHASE 5] Assembling Final Video...")

            # Validate video clips
            video_clips = [s for s in self.state.script.scenes if s.video_path and os.path.exists(s.video_path)]

            if len(video_clips) == 0:
                error_msg = "No video clips available for assembly. All video generation failed."
                print(f"   [FATAL] {error_msg}")
                self.state.add_log(f"[FATAL] {error_msg}")
                self.state.status = "failed"
                self.state.error = error_msg
                self.save_state()
                raise Exception(error_msg)

            if len(video_clips) < len(self.state.script.scenes):
                missing_count = len(self.state.script.scenes) - len(video_clips)
                print(f"   [WARN] {missing_count} scenes failed video generation, proceeding with {len(video_clips)} clips")
                self.state.add_log(f"[WARN] Partial success: {len(video_clips)}/{len(self.state.script.scenes)} scenes")

            try:
                from .providers.composer import Composer
                composer = Composer()

                print(f"   [ASSEMBLY] Composing {len(video_clips)} video clips...")
                self.state.add_log(f"[ASSEMBLY] Composing with transition: {self.state.transition_type}")

                final_path = composer.compose(self.state, transition_type=self.state.transition_type)

                if final_path and os.path.exists(final_path):
                    self.state.final_video_path = final_path
                    self.state.status = "completed"
                    self.save_state()
                    print(f"\n[DONE] Video saved to: {final_path}")
                    self.state.add_log(f"[SUCCESS] Final video: {final_path}")
                else:
                    raise Exception("Composer returned invalid path")

            except Exception as e:
                error_msg = f"Assembly failed: {str(e)}"
                print(f"   [ERROR] {error_msg}")
                self.state.add_log(f"[ERROR] {error_msg}")
                self.state.status = "failed"
                self.state.error = error_msg
                self.save_state()
                raise

            # Mastering disabled for free tier
            self.state.add_log("[MASTERING] 4K Upscale Skipped (Free Tier Active).")

            # Performance Summary
            print("\n" + "="*80)
            print("PIPELINE COMPLETE - PERFORMANCE SUMMARY")
            print("="*80)

            image_success = len([s for s in self.state.script.scenes if s.image_path])
            video_success = len([s for s in self.state.script.scenes if s.video_path])
            vo_success = len([l for l in self.state.script.lines if l.audio_path])
            sfx_success = len([s for s in self.state.script.scenes if s.sfx_path or not s.audio_prompt])

            print(f"Images:  {image_success}/{len(self.state.script.scenes)} scenes")
            print(f"Videos:  {video_success}/{len(self.state.script.scenes)} scenes")
            print(f"VO:      {vo_success}/{len(self.state.script.lines)} lines")
            print(f"SFX:     {sfx_success}/{len(self.state.script.scenes)} scenes")
            print(f"BGM:     {'Yes' if self.state.bgm_path else 'No'}")
            print(f"Final:   {self.state.final_video_path}")
            print("="*80 + "\n")

            self.state.status = "completed"
            self.state.add_log("[APPROVAL_GATE_3] Final assembly complete!")
            self.save_state()

        except Exception as e:
            error_msg = f"Assembly failed: {str(e)}"
            print(f"\n[FATAL ERROR] {error_msg}")

            import traceback
            self.state.add_log(f"[FATAL] {error_msg}")
            self.state.add_log(f"[TRACEBACK] {traceback.format_exc()}")

            self.state.status = "failed"
            self.state.error = error_msg
            self.save_state()
            raise

    def save_state(self):
        plan_path = self._get_plan_path()
        with open(plan_path, "w") as f:
            f.write(self.state.model_dump_json(indent=2))
